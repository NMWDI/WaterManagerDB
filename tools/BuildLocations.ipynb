{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Wells and Locations\n",
    "I have to use data from the extracted meters to build the wells and locations tables before I can properly re-organized the extracted meters data into a table.\n",
    "\n",
    "* Note: This imports extracted_meters.csv. I manually changed some rows in this csv on 7/11, if the csv is regenerated, those changes will be lost and may need to be re-done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load extracted_meters\n",
    "meters = pd.read_csv('./api/data/extracted_meters.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The locations table will consist mostly of well locations, but I also need to include the monitoring wells and storage location(s).\n",
    "\n",
    "Steps:\n",
    "* Create initial locations and wells tables with monitoring wells and storage location(s)\n",
    "* Create a list of wells from RA numbers in extracted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitoring_wells = {\n",
    "    'PoeCorn':(33.613507745151,-104.519169218838),\n",
    "    'TransWestern':(33.5924283752,-104.518961682916),\n",
    "    'Berrendo-Smith':(33.438,-104.512),\n",
    "    'LFD':(33.373029848637,-104.46614919662),\n",
    "    'OrchardPark':(33.257,-104.415),\n",
    "    'Greenfield':(33.16818643207846,-104.43742880081622),\n",
    "    'Bartlett':(33.07014846801758,-104.37718963623047),\n",
    "    'Cottonwood':(32.98,-104.521),\n",
    "    'Zumwalt':(32.880372093723246,-104.42966573225806),\n",
    "    'Artesia':(32.779409,-104.428663)\n",
    "}\n",
    "headquarters = (33.39467308099902, -104.49045710307567)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create initial locations dataframe with fields: name, type_id, latitude, longitude, TRSS, owner_id from monitoring_wells\n",
    "locations_initial = pd.DataFrame.from_dict(monitoring_wells, orient='index', columns=['latitude','longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add on a row for headquarters\n",
    "locations_initial.loc['headquarters'] = headquarters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_initial['type_id'] = 2\n",
    "locations_initial.loc['headquarters','type_id'] = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe with the RA numbers from the extracted data. Only use values associated with installed meters to minimize duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranumbers = meters[meters['meter_status_id'] == 1].loc[:,['sRANumber','sTRSS','latitude','longitude','owner_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop where sRANumber is null\n",
    "ranumbers = ranumbers.dropna(subset=['sRANumber'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to build the locations table from the ra number data but with unique locations as defined by TRSS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_ra = ranumbers.drop_duplicates(subset=['sTRSS'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change sRANumber to name and add on type_id = 2\n",
    "locations_ra = locations_ra.rename(columns={'sRANumber':'name'})\n",
    "locations_ra['type_id'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locations table is the concatenation of locations_initial and locations_ra\n",
    "locations_initial['name'] = locations_initial.index\n",
    "locations_table = pd.concat([locations_initial, locations_ra],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add on a location_id\n",
    "locations_table['location_id'] = locations_table.index + 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will use all the RA numbers to create a wells table. Some will share locations, which might be wrong, but is the best I can do with the data I have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop sorted, duplicated RA numbers, keep first\n",
    "ranumbers = ranumbers.sort_values('sRANumber').drop_duplicates('sRANumber', keep='first')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point there are still a few suspicious RA numbers. One is zero, the others have TRSS of an address. I will drop the zero but leave the others for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop where RA number is 0\n",
    "ranumbers.drop(2076, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add on a location_id to create the wells table\n",
    "wells_table = ranumbers.merge(locations_table[['sTRSS','location_id']], how='left',left_on='sTRSS', right_on='sTRSS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a well_id from integer index on sorted table\n",
    "wells_table = wells_table.sort_values('sRANumber')\n",
    "wells_table['well_id'] = np.arange(1,len(wells_table)+1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save both tables to csv after reorganizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_table = locations_table[['location_id','name','type_id','sTRSS','latitude','longitude','owner_id']]\n",
    "locations_table.to_csv('./api/data/locations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "wells_table['name'] = wells_table['sRANumber']\n",
    "wells_table = wells_table[['well_id','name','sRANumber','location_id']]\n",
    "wells_table.to_csv('./api/data/wells.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
